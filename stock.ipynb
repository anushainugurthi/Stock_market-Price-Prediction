import pandas_datareader as web
import datetime
import requests
import sys
import numpy as np
import tweepy
import os

from keras.models import Sequential
from keras.layers import Dense
from textblob import TextBlob

start = datetime.datetime(2019, 3, 1)
end = datetime.datetime(2019, 4, 1)
stock_data_file = 'stock_data.csv' 

# keys and tokens from the Twitter Dev Console
consumer_key = 'EXbY6iYOHkVYVs500TyLJz9SX'
consumer_secret = '3CFdyt2CzY3FVCpIZ7rtOvHEdDCFrSDzM1UrJOgMbPscHbnzTa'
access_token = '94534174-J8BYknYbc5EP6fuqy2kHjWws5tdn8T1hogN89GkyD'
access_token_secret = 'qfqwzP28MdzLyr7ujbUqCJt7zpRzfJ5cgpMIYywAoS0Cd'

login = tweepy.OAuthHandler(consumer_key, consumer_secret)
login.set_access_token(access_token, access_token_secret)
user = tweepy.API(login)


def main():
    stock_name = input("\n\nWelcome to Stock Prediction using Twitter Analysis and Tensor Flow Algorithm!!\n\n Enter the NYSE stock you want to predict today:  ").upper()
    get_stock_data(stock_name)
    sentiment(stock_name, num = 100)
    stock_predict()

def get_stock_data(stock_name):
    company_name = get_name(stock_name)
    print("\n\nGetting the stock data from the web for "+str(company_name))
    df = web.DataReader(stock_name, 'yahoo', start, end)

    df.to_csv(stock_data_file) 
        
def get_name(symbol):
    url = "http://d.yimg.com/autoc.finance.yahoo.com/autoc?query={}&region=1&lang=en".format(symbol)
    result = requests.get(url).json()
    for x in result['ResultSet']['Result']:
        if x['symbol'] == symbol:
            return x['name']
 
def sentiment(quote, num):

    tweet_list = user.search(get_name(quote), count = num)
    positive = 0
    null = 0
    for tweet in tweet_list:
        check = TextBlob(tweet.text).sentiment
        if check.subjectivity == 0:
            null += 1
            next
        if check.polarity > 0:
            positive += 1

    if positive > ((num - null)/2):
        print ('\n\nThis stock has good sentiment\n\n')
    else:
        print ('\n\nThis stock has bad sentiment\n\n')
        
    print(" The Sentimenatal Analysis created is to help the decision process but should not be taken granted!!")
        
def create_set(data):
    datax = [data[n+1] for n in range(len(data)-2)]
    return np.array(datax), data[2:]        
        
def stock_predict():
    data = []
    with open(stock_data_file) as f:
        for num, line in enumerate(f):
            if num != 0:
                data.append(float(line.split(',')[1]))
        data = np.array(data)

    trainx, trainy = create_set(data)

    classifier = Sequential()
    classifier.add(Dense(8, input_dim = 1, activation = 'relu'))
    classifier.add(Dense(1))
    classifier.compile(loss = 'mean_squared_error', optimizer = 'adam')
    classifier.fit(trainx, trainy, nb_epoch= 200, batch_size = 2, verbose = 2)

    prediction = classifier.predict(np.array([data[0]]))
    print( 'from %s to %s' % (data[0], prediction[0][0]))

   
 
 
if __name__ == '__main__':
    main()
